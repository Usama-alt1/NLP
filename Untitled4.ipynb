{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlXFWcbFVNV41xJCbFP8NG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Usama-alt1/NLP/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers beautifulsoup4 requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjEB3AY81VNy",
        "outputId": "f495dbd4-6efc-49f8-fff4-677b9678b5c0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38BWbfeW2H7x",
        "outputId": "223ce514-678f-4a7e-c3a5-0569e549128f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_dawn_homepage(url=\"https://www.dawn.com/\"):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    articles = []\n",
        "    for article in soup.select('article.story'):\n",
        "        title_tag = article.select_one('h2 a')\n",
        "        if title_tag:\n",
        "            title = title_tag.get_text(strip=True)\n",
        "            link = title_tag['href']\n",
        "            if not link.startswith('http'):\n",
        "                link = \"https://www.dawn.com\" + link\n",
        "            articles.append({\"title\": title, \"url\": link})\n",
        "\n",
        "    return articles"
      ],
      "metadata": {
        "id": "Y2eX5tPr7vQ-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_article_text(article_url):\n",
        "    try:\n",
        "        response = requests.get(article_url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        paragraphs = soup.select('div.story__content p')\n",
        "        content = ' '.join(p.get_text(strip=True) for p in paragraphs)\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {article_url}: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "HVJctljs7x6M"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    try:\n",
        "        if len(text) < 200:\n",
        "            return \"Too short to summarize\"\n",
        "        summary = summarizer(text[:1024], max_length=150, min_length=40, do_sample=False)\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        print(\"Summarization failed:\", e)\n",
        "        return \"Summarization failed\""
      ],
      "metadata": {
        "id": "vKrXZAJz7yTD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    try:\n",
        "        result = sentiment_analyzer(text)[0]\n",
        "        return result['label']  # \"POSITIVE\" or \"NEGATIVE\"\n",
        "    except Exception as e:\n",
        "        print(\"Sentiment analysis failed:\", e)\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "22JM39Ox73w1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline():\n",
        "    news_data = scrape_dawn_homepage()\n",
        "    print(f\"\\nðŸ“° Found {len(news_data)} articles... extracting and analyzing...\\n\")\n",
        "    results = []\n",
        "\n",
        "    for article in news_data[:10]:\n",
        "        title = article[\"title\"]\n",
        "        url = article[\"url\"]\n",
        "        full_text = extract_article_text(url)\n",
        "        summary = summarize_text(full_text)\n",
        "        sentiment = analyze_sentiment(summary)\n",
        "\n",
        "        results.append({\n",
        "            \"Title\": title,\n",
        "            \"URL\": url,\n",
        "            \"Summary\": summary,\n",
        "            \"Sentiment\": sentiment\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"dawn_news_summary_sentiment.csv\", index=False)\n",
        "    print(\"\\nâœ… Saved as 'dawn_news_summary_sentiment.csv'\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x='Sentiment', data=df)\n",
        "    plt.title('Sentiment Analysis of Dawn News Articles')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Number of Articles')\n",
        "    plt.savefig('sentiment_analysis_plot.png')  # Save the plot as a PNG file\n",
        "    plt.show()\n",
        "\n",
        "    # Display the DataFrame with the added 'Sentiment' column\n",
        "    print(df)\n",
        "\n",
        "run_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YE8SY256N82",
        "outputId": "faca9ea8-10b3-420f-fc56-7190eb7a69ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“° Found 106 articles... extracting and analyzing...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('dawn_news_summaries.csv')\n"
      ],
      "metadata": {
        "id": "FQ6zPcVt2KU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XKf0khp01v-E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHXRB_l81wYN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}